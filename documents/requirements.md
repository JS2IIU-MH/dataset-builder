
# 機械学習データ前処理アプリ 要求仕様書

## 1. 目的

機械学習におけるデータ前処理（クリーニング、加工、探索的分析）をGUI上で行い、エンジニアの作業工数を削減する。また、処理内容をコードとして書き出すことで、再現性の確保と本番実装への移行をスムーズにする。

## 2. システム概要

- **プラットフォーム:** Streamlit (Python基盤のWebアプリケーション)
- **主な対象データ:** CSV形式の構造化データ
- **主要ライブラリ:** Pandas, NumPy, Scikit-learn, Plotly/Matplotlib, ydata-profiling

## 3. 機能要件

### 3.1 データ入出力

- **CSVアップロード:** ローカルのCSVファイルをドラッグ＆ドロップで読み込む。
- **プレビュー:** 読み込んだデータの先頭/末尾（5〜10行）の表示。
- **データエクスポート:** 処理後のデータをCSV/Parquet形式でダウンロード。
- **コード出力:** 画面上で行った処理を再現するためのPandas用Pythonコードを自動生成・表示。

### 3.2 探索的データ分析 (EDA)

- **基本統計量表示:** `describe()` に相当する情報の表示（平均、標準偏差、最小、最大、四分位数）。
- **欠損値の可視化:** 各列の欠損数・欠損率の算出とヒートマップ表示。
- **分布の可視化:** 選択した列のヒストグラム、箱ひげ図の生成。
- **相関分析:** 変数間の相関計数を算出し、ヒートマップで表示。

### 3.3 データクリーニング

- **型変換:** 特定の列を「数値」「文字列」「カテゴリ」「日付」に変換。
- **欠損値処理:**
  - 削除（行/列）
  - 補完（平均値、中央値、最頻値、定数）
- **重複削除:** 重複するレコードを一括削除。
- **外れ値処理:** IQR法または3σ法に基づき、外れ値のクリッピング（上限下限での置き換え）または削除。

### 3.4 特徴量エンジニアリング

- **演算処理による新列生成:** 既存の列同士の計算（例: `A列 + B列`）や定数計算。
- **エンコーディング:**
  - One-Hot Encoding（名義尺度向け）
  - Label Encoding（順序尺度向け）
- **スケーリング:** 標準化（StandardScaler）および正規化（MinMaxScaler）。
- **日付特徴量抽出:** 日付型から「年」「月」「曜日」「休日フラグ」を抽出。

## 4. 画面設計（UI/UX）

### 4.1 全体構成

- **サイドバー:**
  - ファイルアップロードUI
  - 現在のデータサイズ（行・列）表示
  - リセットボタン（処理を最初からやり直す）
  - 一括ダウンロードボタン
- **メインエリア（タブ構成）:**
  1. **データ確認:** 統計量、欠損値リスト。
  2. **クリーニング:** 型変換、欠損値・重複処理。
  3. **特徴量作成:** エンコーディング、スケーリング、列演算。
  4. **可視化:** グラフ、相関図。
  5. **エクスポート:** 最終データ確認とPythonソースコード表示。

## 5. 非機能要件

- **操作性:** プログラミング知識がなくても、直感的に前処理の手順を選択できること。
- **処理速度:** 数十万行程度のデータであればストレスなくプレビュー・更新ができること（必要に応じてサンプリング表示を行う）。
- **拡張性:** 将来的に新しいエンコーディング手法やモデル学習機能を追加しやすい構成にすること。

## 6. 将来的な拡張項目（フェーズ2以降）

- **複数ファイルの結合:** Join（横結合）およびUnion（縦結合）機能。
- **自動レポーティング:** `ydata-profiling` による詳細なHTMLレポートの自動生成。
- **モデル簡易学習:** 前処理したデータを用いて、Scikit-learnによる簡易的な学習・精度評価を行う機能。
- **データベース連携:** SQLによる直接データ読み込み。
